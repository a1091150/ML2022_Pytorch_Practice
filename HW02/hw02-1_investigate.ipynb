{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這次作業的要求在 HW02.pdf 中第 10 頁\n",
    "- Simple baseline\n",
    "    - You should able to pass the simple baseline using the sample code provided. --> 什麼都沒更動的時候。\n",
    "- Strong baseline\n",
    "    - Model architecture (layers? dimension? activation function?)\n",
    "    - Training (batch size? optimizer? learning rate? epoch?)\n",
    "    - Tips (batch norm? dropout? regularization?)\n",
    "\n",
    "**這次作業在於要靠自己去嘗試調參數啦！**\n",
    "\n",
    "資料已經處理好了，也不知道長什麼樣子。300 MB 解壓縮後很大包 1.5 GB ，載入花了 22 秒很久，但是使用 Simple baseline 的版本訓練不會太久。\n",
    "\n",
    "擷取資料集：\n",
    "Size of training set: (983945, 429)\n",
    "Size of validation set: (245987, 429)\n",
    "\n",
    "參考：\n",
    "- https://www.youtube.com/watch?v=OP5HcXJg2Aw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture 改進\n",
    "\n",
    "- http://ielab.ie.nthu.edu.tw/108_IIE_project/3/word/108IIE_proj3_107034703_word.pdf\n",
    "- https://hackmd.io/@lido2370/SJMPbNnKN\n",
    "\n",
    "我一開始是想要用 CNN 試試看，但是 CNN 至少要求 2 dimonsion input，而且最好是正方形的輸入，但是我湊不到正方形，所以作罷。另外 CNN 要自己去算輸入與輸出層的 dimension，不會計算導致輸出有誤。\n",
    "\n",
    "後來思考了一下，這個作業是很前期的作業，可能只要用 Fully Connected Layer 去測試就好而已，所以就是多加幾行 FC\n",
    "\n",
    "```python\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.layer2048 = nn.Linear(429, 2048)\n",
    "        self.layer1024 = nn.Linear(2048, 1024)\n",
    "        self.layer512 = nn.Linear(1024, 512)\n",
    "        self.layer256 = nn.Linear(512,256)\n",
    "        self.layer128 = nn.Linear(256, 128)\n",
    "        self.layer39 = nn.Linear(128, 39)\n",
    "        self.out = nn.Linear(128, 39) \n",
    "\n",
    "        self.act_fn = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer2048(x)\n",
    "        x = self.act_fn(x)\n",
    "\n",
    "        x = self.layer1024(x)\n",
    "        x = self.act_fn(x)\n",
    "\n",
    "        x = self.layer512(x)\n",
    "        x = self.act_fn(x)\n",
    "\n",
    "        x = self.layer256(x)\n",
    "        x = self.act_fn(x)\n",
    "\n",
    "        x = self.layer128(x)\n",
    "        x = self.act_fn(x)\n",
    "\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "```\n",
    "\n",
    "epoch 改為 4 次，執行之後的輸出：\n",
    "```\n",
    "[001/004] Train Acc: 0.404591 Loss: 2.054130 | Val Acc: 0.525853 loss: 1.603278\n",
    "saving model with acc 0.526\n",
    "[002/004] Train Acc: 0.560343 Loss: 1.491168 | Val Acc: 0.603922 loss: 1.349655\n",
    "saving model with acc 0.604\n",
    "[003/004] Train Acc: 0.619581 Loss: 1.278985 | Val Acc: 0.637143 loss: 1.211290\n",
    "saving model with acc 0.637\n",
    "[004/004] Train Acc: 0.655806 Loss: 1.143719 | Val Acc: 0.664686 loss: 1.110771\n",
    "saving model with acc 0.665\n",
    "```\n",
    "\n",
    "通常每輪（epoch） 訓練，Acc 通常會多一點點\n",
    "\n",
    "修改 BATCH_SIZE = 32 後，執行第二次的輸出：\n",
    "```\n",
    "[001/004] Train Acc: 0.442119 Loss: 1.917239 | Val Acc: 0.564473 loss: 1.495950\n",
    "saving model with acc 0.564\n",
    "[002/004] Train Acc: 0.595558 Loss: 1.368507 | Val Acc: 0.633241 loss: 1.229036\n",
    "saving model with acc 0.633\n",
    "[003/004] Train Acc: 0.651652 Loss: 1.156283 | Val Acc: 0.668320 loss: 1.095194\n",
    "saving model with acc 0.668\n",
    "[004/004] Train Acc: 0.685776 Loss: 1.032083 | Val Acc: 0.681768 loss: 1.041329\n",
    "saving model with acc 0.682\n",
    "```\n",
    "\n",
    "在其中一層加入 Dropout layer\n",
    "\n",
    "```python\n",
    "    ...\n",
    "    x = self.drop1(x)\n",
    "\n",
    "    x = self.layer128(x)\n",
    "    x = self.act_fn(x)\n",
    "\n",
    "    x = self.out(x)\n",
    "        \n",
    "```\n",
    "\n",
    "輸出：\n",
    "```\n",
    "[001/004] Train Acc: 0.432475 Loss: 1.947828 | Val Acc: 0.555814 loss: 1.510319\n",
    "saving model with acc 0.556\n",
    "[002/004] Train Acc: 0.587345 Loss: 1.393966 | Val Acc: 0.630143 loss: 1.240262\n",
    "saving model with acc 0.630\n",
    "[003/004] Train Acc: 0.643952 Loss: 1.182250 | Val Acc: 0.667779 loss: 1.100147\n",
    "saving model with acc 0.668\n",
    "[004/004] Train Acc: 0.679541 Loss: 1.054692 | Val Acc: 0.682747 loss: 1.038554\n",
    "saving model with acc 0.683\n",
    "```\n",
    "\n",
    "沒什麼變化。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
