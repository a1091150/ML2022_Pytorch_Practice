{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改所有的 ```pin_memory``` 以降低記憶體爆掉的問題。\n",
    "```diff\n",
    "- valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "+ valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=False)\n",
    "```\n",
    "\n",
    "\n",
    "**先做做看 Hard 的要求**，主要參考 HW03.pdf 的最後一頁 Resource 中的提示跟教授的影片。\n",
    "\n",
    "- https://youtu.be/fX_guE7JNnY?t=1163 中提到，怎麼選資料是 open question\n",
    "\n",
    "\n",
    "先嘗試 Entropy-based Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy-based Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "參考 [影片時間](https://youtu.be/fX_guE7JNnY?t=1656) 跟 [Entropy Regularization in Reinforcement Learning](https://towardsdatascience.com/entropy-regularization-in-reinforcement-learning-a6fa6d7598df)\n",
    "\n",
    "公式：\n",
    "$$\n",
    "H(X) = -\\sum\\pi\\left(x\\right)\\log\\left(\\pi\\left(x\\right)\\right) \n",
    "$$\n",
    "\n",
    "若是越集中在某一個 class(以機率或數值表示)，entropy 數值就會接近零。若是平均分佈，數值就會遠離零。對應 python code(下個 Cell)，第三個例子的數值有 0.8 但是離零有段距離，所以 ```get_pseudo_labels``` 的參數 ```threshold``` 要調整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3822855642311125\n",
      "5.52914225692445\n",
      "0.6890721020039956\n",
      "0.9734459322131686\n",
      "(array([0, 4]),)\n",
      "-18.821710777363496\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "q_1 = [0.26, 0.28, 0.24, 0.22]\n",
    "h_1 = -np.sum(q_1*np.log(q_1))\n",
    "print(h_1)\n",
    "\n",
    "q_1 = [0.26, 0.28, 0.24, 0.22] * 4\n",
    "h_1 = -np.sum(q_1*np.log(q_1))\n",
    "print(h_1)\n",
    "\n",
    "q_1 = [0.1, 0.08, 0.8, 0.02]\n",
    "h_1 = -np.sum(q_1*np.log(q_1))\n",
    "print(h_1)\n",
    "\n",
    "q_1 = [0.5, 0.08, 0.5, 0.02]\n",
    "h_1 = -np.sum(q_1*np.log(q_1))\n",
    "print(h_1)\n",
    "\n",
    "q_1 = [0.6, 0.08, 0.4, 0.02]\n",
    "h_1 = -np.sum(q_1*np.log(q_1))\n",
    "\n",
    "print(h_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "b = a > 3\n",
    "c = np.where(b)[0]\n",
    "print(c)\n",
    "print(type(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取出部份資料\n",
    "這裡遇到了一個難題，我要怎麼取出部份資料，並且為 DataSetFolder 型態。\n",
    "在 github 搜尋到 [@1am9trash](https://github.com/1am9trash/Hung_Yi_Lee_ML_2021/blob/main/hw/hw3/hw3_code.ipynb) 撰寫的程式碼，擷取實作程式碼。\n",
    "\n",
    "```python\n",
    "class PseudoDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, id):\n",
    "        return self.x[id][0], self.y[id]\n",
    "\n",
    "......\n",
    "\n",
    "    idx = []\n",
    "    labels = []\n",
    "\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        img, _ = batch\n",
    "        with torch.no_grad():\n",
    "            logits = model(img.to(device))\n",
    "        probs = softmax(logits)\n",
    "\n",
    "        for j, x in enumerate(probs):\n",
    "            if torch.max(x) > threshold:\n",
    "                idx.append(i * batch_size + j)\n",
    "                labels.append(int(torch.argmax(x)))\n",
    "    \n",
    "    dataset = PseudoDataset(Subset(dataset, idx), labels)\n",
    "```\n",
    "\n",
    "最後一段得知可以使用 [Subset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset)，定睛一看發現作業本身就有寫了\n",
    "```python\n",
    "# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "第一個寫法會產生奇怪的問題，改成類似於 @1am9trash 的寫法。\n",
    "\n",
    "第一次的程式碼：\n",
    "```python\n",
    "class PseudogDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        ()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index][0], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "```\n",
    "\n",
    "```python\n",
    "    selected_indices = []\n",
    "    selected_labels = []\n",
    "\n",
    "    # Iterate over the dataset by batches.\n",
    "    for i, batch in enumerate(data_loader):\n",
    "\n",
    "        img, _ = batch\n",
    "\n",
    "        # Forward the data\n",
    "        # Using torch.no_grad() accelerates the forward process.\n",
    "        with torch.no_grad():\n",
    "            logits = model(img.to(device))\n",
    "\n",
    "        # Obtain the probability distributions by applying softmax on logits.\n",
    "        probs = softmax(logits)\n",
    "\n",
    "        # ---------- TODO ----------\n",
    "        # Filter the data and construct a new dataset.\n",
    "        entropy_value = -torch.sum(probs*torch.log(probs), -1)\n",
    "        selected = entropy_value < threshold\n",
    "        selected[0] = True # 測試用\n",
    "        selected[1] = True # 測試用\n",
    "\n",
    "        batch_selected = torch.add(torch.where(selected)[0], i * batch_size)\n",
    "        selected_indices.append(batch_selected)\n",
    "        batch_label = torch.argmax(probs[selected], -1)\n",
    "        selected_labels.append(batch_label)\n",
    "\n",
    "    selected_indices = torch.cat(selected_indices)\n",
    "    selected_labels = torch.cat(selected_labels).int()\n",
    "    \n",
    "    dataset = PseudogDataset(Subset(dataset, selected_indices), selected_labels)\n",
    "```\n",
    "\n",
    "改成以下程式碼：\n",
    "\n",
    "```python\n",
    "    entropy_value = -torch.sum(probs*torch.log(probs), -1)\n",
    "            argmax = torch.argmax(probs, -1)\n",
    "            for j, prob in enumerate(probs):\n",
    "                if entropy_value[j] < threshold:\n",
    "                # if j == 0 or j == 1:\n",
    "                    selected_indices.append(i * batch_size + j)\n",
    "                    selected_labels.append(int(torch.argmax(prob)))\n",
    "\n",
    "dataset = PseudogDataset(Subset(dataset, selected_indices), selected_labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一次改進"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "對比 [@1am9trash](https://github.com/1am9trash/Hung_Yi_Lee_ML_2021/blob/main/hw/hw3/hw3_code.ipynb) 撰寫的程式碼中的提示，要先思考 Easy, Medium 的作業要求。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ktensor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "527308d3d76313f2ba0d81a980b849ed09b1f67a573759b8fbcfe642d4736f37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
